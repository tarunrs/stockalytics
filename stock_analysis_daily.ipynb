{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def get_weekday(date):\n",
    "    return str(datetime.strptime(date, \"%Y-%m-%d\").weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_ticker(ticker, history=60):\n",
    "    data = pd.read_csv(\"raw/\" + ticker + \".csv\")\n",
    "    temp = list(data[\"Close\"].copy())\n",
    "    temp = [0] + temp[:-1]\n",
    "    data[\"prev_close\"] = temp\n",
    "    temp1 = list(data[\"Close\"].copy())\n",
    "    temp1 = [0, 0, 0, 0, 0] + temp1[:-5]\n",
    "    data[\"prev_week_close\"] = temp1\n",
    "    data[\"change\"] = data[\"Close\"] - data[\"prev_close\"]\n",
    "    data[\"change_week\"] = data[\"Close\"] - data[\"prev_week_close\"]\n",
    "    data[\"percentage_change\"] = data[\"change\"] * 100 / data[\"Close\"]\n",
    "    data[\"percentage_change_week\"] = data[\"change_week\"] * 100 / data[\"Close\"]\n",
    "    data = data.drop(data.index[:5])\n",
    "    data = data.dropna(axis=0, how=\"any\")\n",
    "    data = data.reset_index(drop=True)\n",
    "    data[\"weekday\"] = data[\"Date\"].apply(lambda x: get_weekday(x))\n",
    "    data[\"label\"] = data[\"percentage_change\"].apply(lambda x: int(math.floor(x)))\n",
    "    data[\"label\"] = data[\"label\"].apply(lambda x: 10 if x > 10 else x)\n",
    "    data[\"label\"] = data[\"label\"].apply(lambda x: -10 if x < -10 else x)\n",
    "    data[\"label\"] = data[\"label\"].apply(lambda x: str(x + 10))\n",
    "    data[\"label_week\"] = data[\"percentage_change_week\"].apply(lambda x: int(math.floor(x)))\n",
    "    data[\"label_week\"] = data[\"label_week\"].apply(lambda x: 10 if x > 10 else x)\n",
    "    data[\"label_week\"] = data[\"label_week\"].apply(lambda x: -10 if x < -10 else x)\n",
    "    data[\"label_week\"] = data[\"label_week\"].apply(lambda x: str(x + 10))\n",
    "    temp2 = list(data[\"label_week\"].copy())\n",
    "    temp2 = temp2[5:] + [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "    data[\"label_next_week\"] = temp2\n",
    "    for i in range(history, len(data)):\n",
    "        for j in range(1, history + 1):\n",
    "            data.at[i, 'prev_label_' + str(j)] = data.iloc[i - j]['label']\n",
    "            data.at[i, 'prev_label_week_' + str(j)] = data.iloc[i - j]['label_week']\n",
    "    data = data.dropna(axis=0, how=\"any\")\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df, num_train, skip_days=0):\n",
    "    data = df.copy()\n",
    "    del data[\"Volume\"]\n",
    "    del data[\"prev_close\"]\n",
    "    del data[\"change\"]\n",
    "    del data[\"percentage_change\"]\n",
    "    del data[\"Adj Close\"]\n",
    "    del data[\"Open\"]\n",
    "    del data[\"High\"]\n",
    "    del data[\"Low\"]\n",
    "    del data[\"Close\"]\n",
    "    del data[\"Date\"]\n",
    "    labels = data[\"label\"].copy()\n",
    "    del data[\"label\"]\n",
    "    #del data[\"label_week\"]\n",
    "    del data[\"label_next_week\"]\n",
    "    if skip_days:\n",
    "        for i in range(1, skip_days + 1):\n",
    "            del data[\"prev_label_\" + str(i)]\n",
    "            del data[\"prev_label_week_\" + str(i)]\n",
    "    data = pd.get_dummies(data)\n",
    "    train_data = data[:num_train].copy()\n",
    "    train_labels = labels[:num_train].copy()\n",
    "    test_data = data[num_train:].copy()\n",
    "    test_labels = labels[num_train:].copy()\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "def get_average_prediction(probabilities, classes):\n",
    "    ret = []\n",
    "    for p in probabilities:\n",
    "        indexes = p.argsort()[-3:]\n",
    "        labels = classes[indexes]\n",
    "        label = round(np.mean([int(el) for el in labels]))\n",
    "        ret.append(str(int(label)))\n",
    "    return ret\n",
    "\n",
    "def evaluate_confusion_matrix(mat):\n",
    "    results = []\n",
    "    totals = []\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range(21):\n",
    "        if i > 10:\n",
    "            correct += sum(mat[i][11:])\n",
    "            incorrect += sum(mat[i][:11])\n",
    "        else:\n",
    "            correct += sum(mat[i][i:])\n",
    "            incorrect += sum(mat[i][:i])\n",
    "    total = correct + incorrect\n",
    "    #print correct, incorrect, total\n",
    "    return correct / float(total)\n",
    "\n",
    "def get_model(train_data, train_labels, test_data, test_labels):\n",
    "    #print len(train_data), len(train_labels), len(test_data), len(test_labels)\n",
    "    clf = MLPClassifier(alpha=1e-5, hidden_layer_sizes=(200, 100, 100, 100, 100, 200), random_state=1, max_iter=1000)\n",
    "    clf.fit(train_data, train_labels)\n",
    "    train_accuracy = clf.score(train_data, train_labels)\n",
    "    test_accuracy = clf.score(test_data, test_labels)\n",
    "    #print \"Training accuracy(exact):\", train_accuracy\n",
    "    #print \"Test accuracy(exact):\", test_accuracy\n",
    "    #print \"Loss:\", clf.loss_\n",
    "    return clf, clf.loss_, train_accuracy, test_accuracy\n",
    "\n",
    "def evaluate_model(clf, test_data, test_labels):\n",
    "    predicted_labels = clf.predict(test_data)\n",
    "    cm1 = confusion_matrix(predicted_labels, test_labels, labels=[str(i) for i in range(21)])\n",
    "    predicted_probabilities = clf.predict_proba(test_data)\n",
    "    average_labels = get_average_prediction(predicted_probabilities, clf.classes_)\n",
    "    cm2 = confusion_matrix(average_labels, test_labels, labels=[str(i) for i in range(21)])\n",
    "    soft_accuracy_exact = evaluate_confusion_matrix(cm1)\n",
    "    soft_accuracy_avg = evaluate_confusion_matrix(cm2)\n",
    "    #print \"Accuracy exact(soft):\", soft_accuracy_exact\n",
    "    #print \"Accuracy average(soft):\", soft_accuracy_avg\n",
    "    return soft_accuracy_exact, soft_accuracy_avg\n",
    "\n",
    "#print datasets[0][[\"Date\", \"Close\", \"prev_close\", \"label_next_week\", \"label_week\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAHLOG 0.8571428571428571\n",
      "OISL 0.8\n",
      "GKWLIMITED 0.6\n",
      "NAGREEKCAP 0.65\n",
      "GUFICBIO 0.65\n",
      "LYCOS 0.4\n",
      "AUSOMENT 0.6\n",
      "GESHIP 0.7\n",
      "THEMISMED 0.6\n",
      "DOLPHINOFF 0.7\n",
      "KOTAKBANK 0.65\n",
      "INDIANHUME 0.55\n",
      "ORBTEXP 0.5\n",
      "DTIL 0.65\n",
      "BANKBEES 0.6\n",
      "FMGOETZE 0.55\n",
      "KOTAKGOLD 0.55\n",
      "TVSELECT 0.75\n"
     ]
    }
   ],
   "source": [
    "#tickers = [\"INFY\", \"SBIN\", \"APOLLOTYRE\", \"LUMAXTECH\", \"JUBLFOOD\", \"PRAKASH\"]\n",
    "tickers = os.listdir(\"raw\")\n",
    "for symbol in tickers:\n",
    "    results = pickle.load(open(\"results-daily.pkl\")) if os.path.isfile(\"results-daily.pkl\") else dict()\n",
    "    try:\n",
    "        symbol = symbol.split(\".\")[0]\n",
    "        if os.path.isfile(\"models_daily/\" + symbol + \".pkl\"): \n",
    "            print \"Skipping:\", symbol\n",
    "            continue\n",
    "        dataset = analyse_ticker(symbol)\n",
    "        pickle.dump(dataset, open(\"data_daily/\" + symbol + \".pkl\", \"wb\"))\n",
    "        train_split_index = len(dataset) - 20\n",
    "        train_data, train_labels, test_data, test_labels = get_train_test(dataset, train_split_index)\n",
    "        pickle.dump(train_data, open(\"train_daily/\" + symbol + \"_data.pkl\", \"wb\"))\n",
    "        pickle.dump(train_labels, open(\"train_daily/\" + symbol + \"_labels.pkl\", \"wb\"))\n",
    "        pickle.dump(test_data, open(\"test_daily/\" + symbol + \"_data.pkl\", \"wb\"))\n",
    "        pickle.dump(test_labels, open(\"test_daily/\" + symbol + \"_labels.pkl\", \"wb\"))\n",
    "        clf, loss, train_accuracy, test_accuracy = get_model(train_data, train_labels, test_data, test_labels)\n",
    "        soft_accuracy_exact, soft_accuracy_avg = evaluate_model(clf, test_data, test_labels)\n",
    "        results[symbol] = dict()\n",
    "        results[symbol][\"loss\"] = loss\n",
    "        results[symbol][\"train_accuracy\"] = train_accuracy\n",
    "        results[symbol][\"test_accuracy\"] = test_accuracy\n",
    "        results[symbol][\"soft_accuracy_exact\"] = soft_accuracy_exact\n",
    "        results[symbol][\"soft_accuracy_avg\"] = soft_accuracy_avg\n",
    "        print symbol, soft_accuracy_avg\n",
    "        joblib.dump(clf, \"models_daily/\"+ symbol + \".pkl\")\n",
    "    except Exception as e:\n",
    "        print symbol, str(e)\n",
    "    pickle.dump(results, open(\"results-daily.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
